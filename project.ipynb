{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPLEX SCIENCE SYSTEM APPLICATION\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "df = pd.read_csv('/Corruption_Dataset.csv')\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and edges from the DataFrame\n",
    "for _, row in df.iterrows():\n",
    "    G.add_node(row['SourceID'], type=row['SourceType'], sector=row['SourceSector'])\n",
    "    G.add_node(row['TargetID'])\n",
    "    G.add_edge(row['SourceID'], row['TargetID'], relationship=row['RelationshipType'],\n",
    "               amount=row['TransactionAmount'], date=row['TransactionDate'])\n",
    "\n",
    "# Calculate basic network metrics\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "avg_degree = sum(dict(G.degree()).values()) / num_nodes\n",
    "density = nx.density(G)\n",
    "clustering_coefficient = nx.average_clustering(G)\n",
    "\n",
    "metrics_summary = {\n",
    "    \"Number of Nodes\": num_nodes,\n",
    "    \"Number of Edges\": num_edges,\n",
    "    \"Average Degree\": avg_degree,\n",
    "    \"Network Density\": density,\n",
    "    \"Average Clustering Coefficient\": clustering_coefficient\n",
    "}\n",
    "\n",
    "metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VIRTUALIZATION OF THE ABOVE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To manage the complexity, we limit the visualization to a subset of the network\n",
    "H = G.subgraph(list(G.nodes)[:100])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "nx.draw(H, with_labels=True, node_color='lightblue', edge_color='gray',\n",
    "        node_size=50, font_size=8)\n",
    "plt.title(\"Subset of Corruption Network Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NETWORK SCIENCE SYSTEM APPLICATION\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.algorithms import community\n",
    "\n",
    "df = pd.read_csv('/Corruption_Dataset.csv')\n",
    "\n",
    "edges = [(row['SourceID'], row['TargetID']) for _, row in df.iterrows()]\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "communities = community.label_propagation_communities(G)\n",
    "community_map = {node: cid for cid, community in enumerate(communities) for node in community}\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "colors = [community_map[node] for node in G.nodes()]\n",
    "nx.draw_networkx_nodes(G, pos, node_color=colors, node_size=20, alpha=0.8)\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
    "plt.title(\"Network Visualization with Label Propagation Community Detection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EMPERICAL APPROACH APPLICATION\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('/Corruption_Dataset.csv')\n",
    "\n",
    "transaction_stats = df['TransactionAmount'].describe()\n",
    "\n",
    "# Frequency Analysis\n",
    "relationship_type_counts = df['RelationshipType'].value_counts()\n",
    "sector_counts = df['SourceSector'].value_counts()\n",
    "role_counts = df['SourceType'].value_counts()\n",
    "\n",
    "# Temporal Analysis\n",
    "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], errors='coerce')\n",
    "transactions_over_time = df['TransactionDate'].value_counts().sort_index()\n",
    "\n",
    "# Visualizing the trends in transactions over time\n",
    "plt.figure(figsize=(12, 8))\n",
    "transactions_over_time.plot(kind='line')\n",
    "plt.title('Trend of Transactions Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.show()\n",
    "\n",
    "# Outputting the results\n",
    "print(\"Transaction Statistics:\\n\", transaction_stats)\n",
    "print(\"\\nRelationship Type Counts:\\n\", relationship_type_counts)\n",
    "print(\"\\nSector Counts:\\n\", sector_counts)\n",
    "print(\"\\nRole Counts:\\n\", role_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CASE STUDY\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "df = pd.read_csv('/Corruption_Dataset.csv')\n",
    "\n",
    "# Adjust the threshold and sector criteria\n",
    "high_value_threshold = df['TransactionAmount'].quantile(0.85)\n",
    "expanded_suspect_sectors = ['Social Program', 'Non-Profit', 'Government']\n",
    "\n",
    "# Filter the dataset again with the new criteria\n",
    "suspect_transactions = df[(df['TransactionAmount'] >= high_value_threshold) &\n",
    "                              (df['SourceSector'].isin(expanded_suspect_sectors))]\n",
    "\n",
    "\n",
    "if not suspect_transactions.empty:\n",
    "    # Create a subgraph for the suspect transactions\n",
    "    G_suspect = nx.from_pandas_edgelist(suspect_transactions, 'SourceID', 'TargetID',\n",
    "                                        edge_attr=True)\n",
    "\n",
    "    if len(G_suspect) > 0:\n",
    "        # Find communities within the suspect subgraph\n",
    "        communities_suspect = list(nx.algorithms.community.greedy_modularity_communities(G_suspect))\n",
    "\n",
    "        # Convert the 'TransactionDate' to datetime\n",
    "        suspect_transactions['TransactionDate'] = pd.to_datetime(suspect_transactions['TransactionDate'])\n",
    "        # Group by month and sum the transaction amounts\n",
    "        transactions_by_month = suspect_transactions.groupby(suspect_transactions['TransactionDate'].dt.to_period('M'))['TransactionAmount'].sum()\n",
    "\n",
    "        # Plot the high-value suspect transactions over time\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        ax = transactions_by_month.plot(kind='bar', color='skyblue', title='High-Value Suspect Transactions Over Time')\n",
    "        ax.set_xlabel('Month')\n",
    "        ax.set_ylabel('Total Transaction Amount')\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"The suspect subgraph is empty. Adjust your criteria and try again.\")\n",
    "else:\n",
    "    print(\"No suspect transactions were found based on the criteria.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create a table of network metrics decomposed by the 'SourceType' attribute as a layer of information,\n",
    "# we will first need to group the data by 'SourceType' and then calculate the network metrics for each group.\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Load the hypothetical dataset\n",
    "df = pd.read_csv('/Corruption_Dataset.csv')\n",
    "\n",
    "# This function will calculate the required metrics for a given graph\n",
    "def calculate_network_metrics(G):\n",
    "    if G.number_of_nodes() == 0:\n",
    "        # Return None for all metrics if the graph is empty\n",
    "        return (None, None, None, None, None, None)\n",
    "    # Calculate metrics\n",
    "    density = nx.density(G)\n",
    "    avg_degree = np.mean([degree for node, degree in G.degree()])\n",
    "    clustering_coefficient = nx.average_clustering(G)\n",
    "    num_connected_components = nx.number_connected_components(G)\n",
    "    # Diameter and average path length can only be calculated for the largest connected component\n",
    "    if nx.is_connected(G):\n",
    "        diameter = nx.diameter(G)\n",
    "        avg_path_length = nx.average_shortest_path_length(G)\n",
    "    else:\n",
    "        # Use the largest connected component for the calculations\n",
    "        largest_cc = max(nx.connected_components(G), key=len)\n",
    "        subgraph = G.subgraph(largest_cc)\n",
    "        diameter = nx.diameter(subgraph)\n",
    "        avg_path_length = nx.average_shortest_path_length(subgraph)\n",
    "    return (density, avg_degree, clustering_coefficient, num_connected_components, diameter, avg_path_length)\n",
    "\n",
    "# Initialize an empty DataFrame to store the metrics\n",
    "metrics_columns = ['Layer', 'Total Nodes', 'Total Edges', 'Density', 'Average Degree', 'Clustering Coefficient', 'Connected Components', 'Diameter', 'Average Path Length']\n",
    "network_metrics_df = pd.DataFrame(columns=metrics_columns)\n",
    "\n",
    "# Iterate over each unique 'SourceType' to create subgraphs and calculate metrics\n",
    "for source_type in df['SourceType'].unique():\n",
    "    # Filter the DataFrame for the current source type\n",
    "    sub_df = df[df['SourceType'] == source_type]\n",
    "    # Create the graph\n",
    "    sub_G = nx.from_pandas_edgelist(sub_df, 'SourceID', 'TargetID')\n",
    "    # Calculate metrics\n",
    "    density, avg_degree, clustering_coefficient, num_connected_components, diameter, avg_path_length = calculate_network_metrics(sub_G)\n",
    "    # Append the metrics to the DataFrame\n",
    "    network_metrics_df = network_metrics_df.append({\n",
    "        'Layer': source_type,\n",
    "        'Total Nodes': sub_G.number_of_nodes(),\n",
    "        'Total Edges': sub_G.number_of_edges(),\n",
    "        'Density': density,\n",
    "        'Average Degree': avg_degree,\n",
    "        'Clustering Coefficient': clustering_coefficient,\n",
    "        'Connected Components': num_connected_components,\n",
    "        'Diameter': diameter,\n",
    "        'Average Path Length': avg_path_length\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Reorder the DataFrame to match the order in the screenshot\n",
    "network_metrics_df = network_metrics_df[['Layer', 'Total Nodes', 'Total Edges', 'Density', 'Diameter', 'Average Path Length', 'Average Degree', 'Clustering Coefficient', 'Connected Components']]\n",
    "\n",
    "network_metrics_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
